# 🔦 Glow-TTS: Generative Flow for Text-to-Speech

---

## 📌 개요

**Glow-TTS**는 **normalizing flow** 기반의 **non-autoregressive TTS 모델**입니다.

| 특징                              | 설명 |
|-----------------------------------|------|
| 🎯 Non-autoregressive              | 병렬 추론 가능, 빠름 |
| 🔁 Flow 기반                      | invertible → 샘플링 가능 |
| 🎯 Alignment-free + monotonic     | attention 없이 정렬 학습 |
| 🎯 Text → z → Mel-spectrogram     | 오디오 특성 공간 직접 샘플링 |

---

## 🧬 전체 구조 요약

```text
Text → Text Encoder → Alignment Predictor (monotonic)
↓
Length Regulator → z (latent flow)
↓
Inverse Flow → Mel-spectrogram
↓
Vocoder → Waveform
```

---

## 🔁 주요 구성 요소

### 1️⃣ **Text Encoder**
- 텍스트(음소)를 임베딩
- multi-head self-attention 사용

---

### 2️⃣ **Monotonic Alignment Search (MAS)**
- Attention 없이 soft alignment 학습
- Text ↔ Mel frame 정렬
- forward-sum 방식 사용

---

### 3️⃣ **Normalizing Flow (Glow-based)**

- Flow 모델: invertible neural network
- 텍스트 → z → Mel 또는 반대로 Mel → z 가능

```
z = f(x)   # Mel → latent
x = f⁻¹(z) # latent → Mel
```

- Affine coupling + invertible conv 사용

---

## 🧪 예시: 작동 흐름 (PyTorch 스타일)

```python
# 1. 텍스트 입력 → 텍스트 인코딩
text = "hello world"
phonemes = tokenizer(text)  # → [HH, EH, L, OW, ...]
x_text = text_encoder(phonemes)  # [B, T, D]

# 2. 정렬 길이 예측 (Monotonic Alignment)
durations = duration_predictor(x_text)
length_regulated = length_regulator(x_text, durations)

# 3. Mel target → z (학습 시)
z = flow.forward(mel_target, length_regulated)  # z = f(x)

# 4. 샘플링 시: 샘플 z → mel
z_sample = torch.randn_like(z)
mel_generated = flow.reverse(z_sample, length_regulated)  # x = f⁻¹(z)
```

---

## 🧠 Alignment-Free 정렬

Glow-TTS는 attention을 쓰지 않고도 alignment를 찾습니다.

| 기존 방식         | Glow-TTS 방식          |
|------------------|------------------------|
| Attention        | Monotonic Alignment Search (MAS) |
| 복잡하고 불안정   | 단방향 정렬로 안정적 학습       |
| 디코더 의존적     | Flow만으로 alignment 학습 가능  |

---

## 🎨 구조 요약도

```text
[Text] ──▶ [Text Encoder] ──▶ [Length Regulator] ──▶ [Flow Decoder] ──▶ [Mel]
                                    ▲
                        [Monotonic Alignment]
```

---

## 📊 Loss 구성

| Loss 구성        | 설명                                      |
|------------------|-------------------------------------------|
| Reconstruction   | Flow로부터 복원한 mel vs GT mel          |
| Duration Loss    | 예측한 duration vs 실제 길이              |
| KL Divergence    | z ~ N(0,1)로 정규화                       |

---

## 💡 왜 Flow를 쓰나?

- invertible → 학습 시 mel → z, 생성 시 z → mel 가능
- 모델 전체가 확률 모델로 동작
- 샘플링을 통해 자연스러운 음성 다양성 확보 가능

---

## ✅ 장단점 요약

| 장점                                   | 단점                    |
|----------------------------------------|-------------------------|
| 병렬 추론 가능 (fast inference)        | 복잡한 구조 (flow 구성) |
| attention 없이 안정적 alignment 학습   | vocoder 필요 (WaveGlow, HiFi-GAN 등) |
| 확률적 샘플링 가능 (prosody 다양성 ↑) | 음성 품질은 VITS보다 약간 낮음 |

---

## 📘 논문 정보

- **Title**: *Non-Autoregressive Flow-Based Acoustic Model for TTS*
- **Authors**: Kim et al., NeurIPS 2020
- **Paper**: https://arxiv.org/abs/2005.11129
- **Code**: https://github.com/jaywalnut310/glow-tts

---

## ✅ 최종 정리

| 항목         | 설명                                           |
|--------------|------------------------------------------------|
| 입력         | 음소 시퀀스                                   |
| 중간 표현     | latent z (flow로 추정)                        |
| 출력         | mel-spectrogram                                |
| 정렬 방식     | monotonic alignment                           |
| 핵심 기술     | flow + alignment search                       |
| 장점         | 병렬 추론, 샘플링 가능, 안정적 학습           |

---

> 🎯 **Glow-TTS는 non-autoregressive TTS의 대표적인 성공 모델**이며,  
> 이후의 Grad-TTS, Diff-TTS 등 flow/diffusion 기반 구조의 기반이 되었습니다.
