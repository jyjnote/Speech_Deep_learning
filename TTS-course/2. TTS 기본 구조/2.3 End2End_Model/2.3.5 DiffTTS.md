# ğŸŒªï¸ DiffTTS: Denoising Diffusion Probabilistic Model for TTS

---

## ğŸ“Œ ê°œìš”

**DiffTTS**ëŠ” ìµœì´ˆë¡œ diffusion probabilistic modelì„ **TTSì˜ mel-spectrogram ìƒì„±**ì— ì ìš©í•œ ëª¨ë¸ì…ë‹ˆë‹¤.  
íŠ¹ì§• ìš”ì•½:

| í•­ëª©                  | ë‚´ìš© |
|-----------------------|------|
| ğŸ¯ ëª©ì                 | í…ìŠ¤íŠ¸ë¡œë¶€í„° ìì—°ìŠ¤ëŸ¬ìš´ mel-spectrogram ìƒì„± |
| ğŸŒ€ ë°©ë²•                | ë…¸ì´ì¦ˆì—ì„œ ì‹œì‘í•´ ì ì§„ì ìœ¼ë¡œ denoiseí•˜ì—¬ mel ìƒì„± |
| ğŸ—ï¸ êµ¬ì„±                | text encoder + duration + diffusion decoder |
| ğŸš« attention ì—†ìŒ      | alignment-free (durationë§Œ ì‚¬ìš©) |

---

## ğŸ” ì‘ë™ íë¦„ ìš”ì•½

```text
Text â†’ Phoneme Encoder â†’ Duration Predictor â†’ zâ‚€ (noise) â†’ ... â†’ Mel
```

í›ˆë ¨ ì‹œ:
```text
Mel â†’ Forward Noise â†’ z_t
    â†“
text ì¡°ê±´ê³¼ í•¨ê»˜ denoise í•™ìŠµ
```

ì¶”ë¡  ì‹œ:
```text
z_T ~ N(0, I) â†’ text ì¡°ê±´ ê¸°ë°˜ denoise â†’ Mel â†’ Vocoder â†’ Waveform
```

---

## ğŸ§  Diffusion ìˆ˜ì‹ (ê¸°ì´ˆ)

### ğŸ”¹ Forward process (ë…¸ì´ì¦ˆ ì¶”ê°€)
```math
q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I)
```

### ğŸ”¹ Reverse process (denoise)

```math
x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \cdot \epsilon_\theta(x_t, t, c) \right)
```

ì—¬ê¸°ì„œ:

- $( x_t $): noisy mel
- $( c $): í…ìŠ¤íŠ¸ ì¡°ê±´ (text encoder ì¶œë ¥)
- $( \epsilon_\theta $): í˜„ì¬ ìƒíƒœì—ì„œ ë…¸ì´ì¦ˆë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì‹ ê²½ë§ (U-Net ë“±)

---

## ğŸ§ª ì˜ˆì‹œ ë°ì´í„° íë¦„ (Step-by-Step)

### 1. ì…ë ¥ í…ìŠ¤íŠ¸: `"hi"`
```python
text = "hi"
phonemes = ['HH', 'AY']
text_embed = text_encoder(phonemes)  # [1, 2, D]
```

### 2. Duration ì˜ˆì¸¡ â†’ Length Regulate
```python
dur = [3, 5]  # ì˜ˆ: HH = 3í”„ë ˆì„, AY = 5í”„ë ˆì„
text_expanded = length_regulator(text_embed, dur)  # â†’ [1, 8, D]
```

### 3. GT mel â†’ forward noise (í•™ìŠµ ì‹œ)
```python
mel_gt = extract_mel(waveform)  # [1, 8, 80]
t = random.randint(1, T)
noise = torch.randn_like(mel_gt)
x_t = sqrt_alpha_bar[t] * mel_gt + sqrt_one_minus_alpha_bar[t] * noise
```

### 4. ëª¨ë¸ í•™ìŠµ: ë…¸ì´ì¦ˆ ì˜ˆì¸¡
```python
pred_noise = epsilon_theta(x_t, t, cond=text_expanded)
loss = F.mse_loss(pred_noise, noise)
```

### 5. ì¶”ë¡  ì‹œ: z_T â†’ mel
```python
z_t = torch.randn([1, 8, 80])
for t in reversed(range(1, T+1)):
    pred_noise = epsilon_theta(z_t, t, cond=text_expanded)
    z_t = reverse_step(z_t, pred_noise, t)
```

---

## ğŸ§© DiffTTS ì£¼ìš” êµ¬ì„± ëª¨ë“ˆ

| ëª¨ë“ˆ                  | ì„¤ëª… |
|------------------------|------|
| **Text Encoder**       | ìŒì†Œ ì„ë² ë”© ë° contextual encoding (Conv + attention ë“±) |
| **Duration Predictor** | ì •ë ¬ì„ ìœ„í•œ ë©œ í”„ë ˆì„ ìˆ˜ ì˜ˆì¸¡ |
| **Length Regulator**   | í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ë©œ ê¸¸ì´ì— ë§ê²Œ ë³µì œ |
| **Denoiser (UNet)**    | ê° stepì˜ ë…¸ì´ì¦ˆ ì œê±° ì˜ˆì¸¡ê¸° |
| **Vocoder**            | mel â†’ waveform (HiFi-GAN ë“± ì‚¬ìš©) |

---

## ğŸ“ˆ Loss êµ¬ì„±

```text
L_total = E[ || Îµ - Îµ_Î¸(x_t, t, c) ||^2 ] + duration loss
```

- Diffusion Loss: ë…¸ì´ì¦ˆ ì˜ˆì¸¡ ì •ë°€ë„
- Duration Loss: ì˜ˆì¸¡ëœ í”„ë ˆì„ ìˆ˜ ì •í™•ë„

---

## ğŸ§  DiffTTS vs Grad-TTS vs Glow-TTS

| í•­ëª©        | DiffTTS               | Grad-TTS              | Glow-TTS                |
|-------------|------------------------|------------------------|--------------------------|
| êµ¬ì¡°        | ê°€ì¥ ë‹¨ìˆœí•œ diffusion | latent space diffusion | flow ê¸°ë°˜ invertible     |
| ì •ë ¬ ë°©ì‹   | duration ì‚¬ìš©          | duration ì‚¬ìš©          | monotonic alignment search |
| í’ˆì§ˆ        | ì¢‹ìŒ (prosody ë‹¤ì–‘ì„±) | ë” ì¢‹ìŒ (ìš´ìœ¨ ìì—°ìŠ¤ëŸ¬ì›€ â†‘) | ë¹ ë¦„, í’ˆì§ˆ ì¢‹ìŒ           |
| ì¶”ë¡  ì†ë„   | ëŠë¦¼ (T step ë°˜ë³µ)     | ëŠë¦¼                   | ë¹ ë¦„ (1 pass)            |
| ìš©ë„ ì í•©ì„± | ì—°êµ¬, ê¸°ë°˜ ì‹¤í—˜ìš©      | ê³ í’ˆì§ˆ ìŒì„± ìƒì„±       | ë¹ ë¥¸ ì‹¤ì„œë¹„ìŠ¤ì— ì í•©      |

---

## ğŸ“˜ ë…¼ë¬¸ ì •ë³´

- **Title**: Diff-TTS: A Denoising Diffusion Model for Text-to-Speech
- **Authors**: Kim et al., 2020
- **Paper**: https://arxiv.org/abs/2104.01409
- **Code**: https://github.com/ericwang2006/Diff-TTS-PyTorch

---

## âœ… ì •ë¦¬ ìš”ì•½

| í•­ëª©          | ì„¤ëª…                                  |
|---------------|---------------------------------------|
| ëª©ì           | Text â†’ Mel with diffusion             |
| í›ˆë ¨ ë°©ì‹      | GT mel + noise â†’ denoise prediction    |
| ì¶”ë¡  ë°©ì‹      | noise â†’ mel (step-by-step sampling)   |
| ì •ë ¬ ë°©ì‹      | duration predictor ì‚¬ìš©               |
| íŠ¹ì§•           | attention-free, ë†’ì€ í’ˆì§ˆ, ëŠë¦° ì†ë„  |

---

> ğŸŒ€ DiffTTSëŠ” **TTS + Diffusionì˜ ì²« ê²°í•© ì‹¤í—˜**ìœ¼ë¡œ,  
> ì´í›„ Grad-TTS, StyleTTS2, FastDiff,
