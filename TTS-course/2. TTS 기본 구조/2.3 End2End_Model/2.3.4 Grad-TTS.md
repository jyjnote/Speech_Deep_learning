# 🌫️ Grad-TTS: Denoising Diffusion 기반 TTS 모델

---

## 📌 개요

**Grad-TTS**는 **Diffusion Probabilistic Model**을  
TTS의 **Text → Mel Spectrogram** 생성에 적용한 **non-autoregressive 모델**입니다.

| 특징                       | 설명 |
|----------------------------|------|
| 🌀 Diffusion 모델 기반       | 노이즈 → 멜로 점진적 정제 |
| ⏱️ Non-autoregressive       | 병렬 생성 가능 |
| 🎯 Explicit duration 사용    | Text ↔ Mel frame 정렬 안정 |

---

## 🔬 작동 원리 요약

Grad-TTS는 다음과 같은 과정을 따릅니다:

```text
Text → Phoneme Encoder → Duration Predictor → z₀ (noise) → ... → Mel
```

- **훈련 시**: mel → z₀ (forward noise), z₀ → mel (reverse process)
- **추론 시**: noise z₀에서 mel을 점진적으로 복원

---

## 🧠 Diffusion 개념 복습

- 목표: noise 벡터 z₀에서 step-by-step으로 mel-spectrogram 생성
- 각 step t에서는 denoising model이 예측 수행

```math
z_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( z_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \cdot \epsilon_\theta(z_t, t, c) \right)
```

- \( \epsilon_\theta \): 현재 noisy 상태에서 noise를 예측하는 neural network
- \( c \): 조건 정보 (텍스트 임베딩 등)

---

## 🧬 전체 구조 요약

```text
[Text] ──▶ [Phoneme Encoder] ──▶ [Duration Predictor] ──▶ [Length Regulator] ──▶ [z₀ + Diffusion Steps] ──▶ [Mel]
```

---

## 🧪 예시: 작동 흐름 (PyTorch 스타일)

```python
# 1. 입력 텍스트 임베딩
text = "hello world"
phonemes = tokenizer(text)                # ['HH', 'EH', 'L', 'OW', ...]
text_feat = encoder(phonemes)             # [B, T, D]

# 2. Duration 예측 및 길이 확장
durations = duration_predictor(text_feat) # [B, T]
expanded_feat = length_regulator(text_feat, durations)  # [B, N, D] N: mel frame

# 3. 학습 시: GT mel → noise z₀
mel_gt = extract_mel(wav)
z0 = noise_forward_process(mel_gt)        # mel → z₀

# 4. Diffusion 모델 훈련: z₀ → mel 복원
z_recon = diffusion_model(z0, expanded_feat)  # denoise
loss = MSE(z_recon, mel_gt)

# 5. 추론 시: z₀ = randn → mel
z0 = torch.randn_like(expanded_feat)
mel_gen = diffusion_model.infer(z0, expanded_feat, T=100)  # reverse steps
```

---

## 🔁 주요 구성 모듈

| 모듈명              | 역할 |
|---------------------|------|
| Phoneme Encoder     | 텍스트(음소) → 임베딩              |
| Duration Predictor  | 음소별 멜 길이 예측 (정렬 학습)    |
| Diffusion Decoder   | 노이즈 z₀에서 멜 생성 (T step 반복) |

---

## 🔧 Loss 구성

| 이름            | 설명                                      |
|-----------------|-------------------------------------------|
| Diffusion Loss  | z₀ → mel 복원 시 MSE (Denoising score)   |
| Duration Loss   | GT duration과 예측 duration 간 거리       |

---

## 📊 학습/추론 흐름 요약

### 🧪 학습 단계

```text
[GT mel] → forward diffusion → z₀
       ↓
[z₀] + [text 조건] → reverse → mel_hat
       ↓
L = MSE(mel_hat, mel_gt) + duration_loss
```

### 🧪 추론 단계

```text
z₀ ~ N(0, I)
    ↓
reverse diffusion using text
    ↓
mel_gen → vocoder → waveform
```

---

## 🎨 직관적 그림

```text
┌────────────┐   ┌────────────┐   ┌──────────┐   ┌────────────┐
│   Text     │ → │ Phoneme Enc│ → │ Duration │ → │ Length Reg │
└────────────┘   └────────────┘   └──────────┘   └────────────┘
                                                     ↓
                                               ┌────────────┐
                                               │  z₀ (noise)│
                                               └────────────┘
                                                     ↓
                                        ┌────────────────────────┐
                                        │  Diffusion Decoder      │
                                        └────────────────────────┘
                                                     ↓
                                                Mel-Spectrogram
```
# 1. Diffusion 수식/계산 원리 상세
### 🔁 1.1 Forward Process (노이즈 추가)

훈련 시, mel-spectrogram \( x_0 \)에 점진적으로 가우시안 노이즈를 더해 \( x_T \)까지 변형합니다.

```math
q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{\alpha_t} x_{t-1}, (1 - \alpha_t) I)
```

누적식:

```math
q(x_t | x_0) = \mathcal{N}(x_t; \sqrt{\bar{\alpha}_t} x_0, (1 - \bar{\alpha}_t) I)
```

여기서,

- \( \alpha_t \): 시간 step별 유지 비율
- \( \bar{\alpha}_t = \prod_{s=1}^t \alpha_s \)

---

### 🔁 1.2 Reverse Process (denoise 단계)

목표: 노이즈 \( x_T \sim \mathcal{N}(0, I) \)에서 원래 mel \( x_0 \)을 복원.

```math
p_\theta(x_{t-1} | x_t, c) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t, c), \Sigma_\theta)
```

보통 \( \mu \)를 다음처럼 구성합니다:

```math
\mu_\theta(x_t, t, c) = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \cdot \epsilon_\theta(x_t, t, c) \right)
```

여기서,

- \( \epsilon_\theta \): 조건부 U-Net (text conditioning 포함)
- \( c \): 텍스트 인코더에서 얻은 임베딩

---

### ✅ 훈련 목표

```math
\mathcal{L}_{diffusion} = \mathbb{E}_{x_0, t, \epsilon} \left[ \left\| \epsilon - \epsilon_\theta(x_t, t, c) \right\|_2^2 \right]
```
# 2. Step-by-Step 예시: "hello" → waveform
### 🧪 입력: "hello"

1. **Phoneme**: [HH, EH, L, OW]
2. **Text Encoder 출력**: shape [B, T=4, D=256]

---

### 🔁 Duration Prediction
- duration: [2, 4, 3, 5] → 총 mel frame 14개
- Length Regulator → shape [B, 14, 256]

---

### 🌀 Diffusion Reverse Sampling
```python
# z₀: Gaussian noise
z0 = torch.randn([1, 14, 80])

# Reverse diffusion (100 step)
mel_hat = z0
for t in reversed(range(1, 101)):
    noise = diffusion_model.eps_theta(mel_hat, t, text_embedding)
    mel_hat = denoise_step(mel_hat, noise, t)
```

---

### 🔉 Mel → Waveform
- mel_hat → vocoder (e.g., HiFi-GAN) → waveform

# 3. Duration Predictor 작동 원리
### ⏱️ Duration Predictor란?

텍스트(음소) 입력에 대해 **몇 개의 mel frame이 할당되어야 하는지** 예측하는 모듈.

---

### 🔁 작동 흐름

```text
Input: phoneme embeddings → duration predictor → [3, 2, 4, 1]  (프레임 길이)
→ Length Regulator로 멜 시퀀스 길이 조정 → [B, T_mel, D]
```

---

### ✅ 학습 방법

- GT alignment (Forced Alignment 또는 MFA로 추출) 사용
- Loss: MSE 또는 L1 between predicted vs GT durations

```python
dur_gt = [2, 3, 4, 5]
dur_pred = duration_predictor(text_feat)
loss = F.mse_loss(dur_pred, dur_gt)
```

---

### 📌 왜 중요한가?

- **attention-free 구조**를 가능하게 함
- 각 음소의 시간 분포를 명시적으로 제공 → **정렬 안정성 ↑**
- inference 시에도 mel 길이 직접 조절 가능

---

### 🧠 참고

Grad-TTS는 **Monotonic Alignment Search (MAS)**를 쓰지 않고  
GT alignment를 기반으로 duration predictor를 안정적으로 학습합니다.

# 4. Grad-TTS vs VITS 비교
| 항목               | Grad-TTS                          | VITS                             |
|--------------------|-----------------------------------|----------------------------------|
| 구조               | Text → Duration → Diffusion → Mel| VAE + Flow + GAN (통합형)        |
| 샘플링 구조        | Step-by-step denoising (느림)     | 빠름 (1 pass)                   |
| 정렬 방식          | Explicit Duration Predictor        | Flow 기반 soft alignment        |
| 멜 다양성/운율      | 확률성 ↑ (high prosody quality)   | Flow 제약 내 다양성             |
| 복원 메커니즘      | Gaussian noise → mel 복원          | latent z → decoder               |
| 음질               | 아주 우수 (느리지만 자연스러움)    | 매우 우수 (속도 + 품질 trade-off)|
| 훈련/추론 난이도   | 고비용 (메모리, 시간 ↑)           | 중간~고                         |

---

## ✅ 장단점 요약

| 장점                             | 단점                    |
|----------------------------------|-------------------------|
| 매우 자연스러운 운율, 발음        | 추론 시간 오래 걸림 (T step 반복) |
| alignment-free + stable 학습     | GPU 메모리/연산량 ↑     |
| 확률적 샘플링 가능 (다양성 ↑)    | vocoder 필요            |

---

## 📘 논문 정보

- **Title**: Grad-TTS: A Diffusion Probabilistic Model for TTS
- **Authors**: Popov et al. (Yandex)
- **Paper**: https://arxiv.org/abs/2105.06337
- **Code**: https://github.com/huawei-noah/Speech-Backbones/tree/main/Grad-TTS

---

## ✅ 정리

| 항목         | 설명                                      |
|--------------|-------------------------------------------|
| 입력         | 음소 시퀀스 (Text)                        |
| 중간 표현     | latent z₀ (noise)                         |
| 생성 방식     | diffusion step-by-step denoising         |
| 정렬 방식     | duration predictor 사용 (explicit length) |
| 장점         | 매우 자연스러운 멜 생성                   |

---

> 🌫️ Grad-TTS는 TTS 분야에 **Diffusion**을 성공적으로 적용한  
> 혁신적인 구조로 이후 **DiffTTS, StyleTTS2, VALL-E** 등에 큰 영향을 주었습니다.
