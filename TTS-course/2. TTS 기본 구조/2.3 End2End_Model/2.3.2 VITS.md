# 🔬 VITS: Variational Inference TTS with adversarial learning

---

## 📌 개요

**VITS**는 **텍스트 → 오디오** 전체 파이프라인을 통합한 **End-to-End TTS 모델**입니다.  
특징:

| 요소     | 내용                                                            |
|----------|-----------------------------------------------------------------|
| VAE      | 음성 → 잠재 변수 `z`로 인코딩, 샘플링                           |
| Flow     | 텍스트 → `z` 분포 예측 (prior), 정렬 정보 학습                 |
| GAN      | 고품질 오디오 생성 (HiFi-GAN 기반 decoder 사용)                |
| Alignment-Free | attention 없이 duration을 flow가 학습하여 alignment 자동 획득 |

---

## 🧬 전체 구조 흐름

```text
Text → Phoneme → Flow-based Prior (p(z|y)) ─┐
                                            │
                                            ├── z → Decoder → waveform
                                            │
Speech → Posterior Encoder (q(z|x)) ────────┘

            ▲                         │
            └────── KL Loss ◀────────┘
```

---

## 🔁 주요 모듈별 설명

### 1️⃣ Posterior Encoder (q(z|x))
- 입력 음성 waveform → latent 벡터 z로 압축
- 정규분포 파라미터 출력: μ, logσ²

```python
mu, logvar = posterior_encoder(x)
z_post = mu + std * eps  # reparameterization
```

---

### 2️⃣ Prior Flow (p(z|y))
- 텍스트로부터 z의 분포 생성 (normalizing flow 사용)
- duration 정보도 flow 안에서 추정됨

```python
z_prior = flow(text_features)
```

---

### 3️⃣ Decoder (Vocoder)
- HiFi-GAN 기반
- z를 입력으로 받아 waveform을 생성
```python
waveform = generator(z)
```

---

### 4️⃣ Discriminator (GAN)
- 실제 vs 생성된 waveform을 구별
- Generator는 이를 속이도록 학습함

---

## 🧠 주요 Loss 구성

| Loss 이름         | 설명                                                   |
|-------------------|--------------------------------------------------------|
| KL Divergence     | posterior `q(z|x)`와 prior `p(z|y)` 사이 정규화         |
| GAN Loss          | discriminator(fake)와 real 구분                         |
| Feature Matching  | D(real)와 D(fake)의 중간 layer 출력 비교                |
| STFT Loss         | waveform → STFT 후 GT와 비교                            |

---

## 🧪 예시 데이터 흐름 (PyTorch 스타일)

```python
# 1. 입력 준비
text = "hello world"
phonemes = phonemize(text)            # → [HH, AH, L, OW, ...]
x = waveform_tensor                   # shape: [1, T]

# 2. Posterior: 음성 → z
mu, logvar = posterior_encoder(x)
std = torch.exp(0.5 * logvar)
eps = torch.randn_like(std)
z_post = mu + std * eps               # q(z|x)

# 3. Prior: 텍스트 → flow → z_pred
z_prior, logdet = flow(phonemes)      # p(z|y)

# 4. Decoder: z → waveform
y_hat = generator(z_post)

# 5. Discriminator: 진짜 vs 가짜
D_real = discriminator(x)
D_fake = discriminator(y_hat)

# 6. Loss 계산
kl_loss = kl_divergence(mu, logvar)   # regularize posterior
gan_loss = compute_gan_loss(D_real, D_fake)
recon_loss = stft_loss(y_hat, x)
```

---

## 🎨 그림으로 요약

```text
┌────────────┐       ┌────────────┐       ┌─────────────┐
│ Text/Phon. │─────▶│ Prior Flow │─────▶ │   z_prior   │
└────────────┘       └────────────┘       └─────┬───────┘
                                                │
    ┌────────────┐      z_post      ┌──────────▼─────────┐
    │  Waveform  │──────▶ Posterior │     Decoder (GAN)  │─────▶ y_hat
    └────────────┘       Encoder    └────────────────────┘
            ▲                      ▲
            │                      └──── KL Loss
            └────────────────────────── Feature Matching
```

---

## 🧠 Alignment-Free 원리

- 전통 attention 없이
- flow 내부에서 duration 추정 → soft alignment
- 모듈 간에 attention alignment가 필요 없음 (자동 학습)

---

## 📘 논문 정보

- **Title:** *Conditional Variational Autoencoder with Adversarial Learning for End-to-End TTS*
- **Authors:** Jaehyeon Kim, Jungil Kong, Juhee Son (Kakao Brain)
- **Link:** https://arxiv.org/abs/2106.06103
- **Code:** https://github.com/jaywalnut310/vits

---

## ✅ 정리 요약

| 항목             | 설명                                        |
|------------------|---------------------------------------------|
| 구조             | VAE + Flow + HiFi-GAN + Discriminator       |
| 입력             | 텍스트 or 음소                              |
| 출력             | Waveform (1D PCM 오디오)                    |
| 특징             | High-quality, end-to-end, fast-ish          |
| 핵심 장점        | alignment-free, 고음질, 통합형 구조          |

---

> ✅ **VITS는 현재 TTS의 품질 기준을 크게 끌어올린 혁신적인 구조**입니다.  
> 다양한 변형 (YourTTS, VITS2, VALL-E)에서도 기반이 됩니다.
