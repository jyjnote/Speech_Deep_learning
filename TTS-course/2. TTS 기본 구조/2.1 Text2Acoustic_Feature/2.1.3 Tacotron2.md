# 🎙️ Tacotron 2: 고품질 End-to-End 음성 합성 (2018)

---

## 📌 개요

**Tacotron 2**는 Google이 발표한 **2단계 End-to-End TTS 시스템**입니다.  
텍스트를 **Mel-Spectrogram**으로 예측한 뒤, **WaveNet vocoder**로 waveform을 생성합니다.

> ✅ Tacotron 1보다 음질이 **비약적으로 향상**된 모델입니다.

---

## 🧬 전체 구조

```text
텍스트
 ↓
Text Embedding
 ↓
Encoder (CNN + BiLSTM)
 ↓
Attention (Location-sensitive)
 ↓
Decoder (Autoregressive LSTM)
 ↓
Mel-Spectrogram (80 × T)
 ↓
Postnet (CNN)
 ↓
Vocoder (WaveNet / HiFi-GAN)
 ↓
Waveform (.wav)
```

---

## 📦 구성 요소별 설명

### 1️⃣ Text Embedding
- character or phoneme 시퀀스를 고정차원 벡터로 변환  
- 임베딩 차원 보통 512

---

### 2️⃣ Encoder: CNN + BiLSTM

- Conv Layer: local context 학습 (3×1 conv, padding 유지)
- BiLSTM Layer: global context 학습 (양방향 처리)

```text
입력: "사랑해" → ['ㅅ', 'ㅏ', 'ㄹ', 'ㅏ', 'ㅇ', 'ㅎ', 'ㅐ']
→ 임베딩 (7, 512)
→ Encoder 출력 (7, 512)
```

---

### 3️⃣ Attention (Location-Sensitive)

- Decoder가 현재 예측 시점에서 입력의 어느 위치를 볼지 soft하게 선택  
- 연속적이고 안정적인 alignment 제공 (글자-프레임 매핑)

---

### 4️⃣ Decoder: Autoregressive LSTM

- 이전 mel frame을 입력으로 받아 다음 frame을 예측
- 하나의 step마다 **r=1~5** frame씩 생성
- dropout, teacher forcing 적용

```text
입력: [<GO>], 이전 mel
출력: mel frame (80 dim)
```

---

### 5️⃣ Postnet

- 5-layer 1D CNN으로 mel 예측값 보정  
- 전체 mel 예측값에 residual 추가

---

### 6️⃣ Vocoder: WaveNet or HiFi-GAN

- 예측된 mel-spectrogram을 실제 waveform으로 변환  
- Tacotron 2는 **WaveNet**을 사용했지만, 현재는 **HiFi-GAN, UnivNet**이 더 빠르고 정확

---

## ⚙️ 실제 예시: "사랑해" 합성

### 🧾 입력 텍스트

```text
문장: "사랑해"
음소 시퀀스: ['ㅅ', 'ㅏ', 'ㄹ', 'ㅏ', 'ㅇ', 'ㅎ', 'ㅐ']
```

### ➡️ 처리 흐름

```text
1. Embedding: [7, 512]  (음소 7개, 512차원)
2. Encoder (CNN + BiLSTM): [7, 512]
3. Attention Context: [1, 512]  (Decoder가 현재 참조하는 입력 정보)
4. Decoder (LSTM): [1, 80]  (mel frame 1개 생성)
5. 반복적으로 mel frame 생성 → mel-spectrogram (예: [80, 120])
6. Postnet: 보정 mel → [80, 120]
7. Vocoder: HiFi-GAN(mel) → waveform (.wav)
```

---

### 📈 시각화 (Mel 예측 결과)

```python
import matplotlib.pyplot as plt
import librosa.display

plt.figure(figsize=(10, 4))
librosa.display.specshow(mel_output, sr=22050, hop_length=256, x_axis='time', y_axis='mel')
plt.colorbar()
plt.title("Tacotron 2: Mel-spectrogram for '사랑해'")
plt.tight_layout()
plt.show()
```

---

## 🔁 핵심 특징 요약

| 항목          | Tacotron 1                            | Tacotron 2                             |
|---------------|----------------------------------------|-----------------------------------------|
| Encoder       | CBHG (Conv Bank + GRU)                | CNN + BiLSTM                            |
| Decoder       | Autoregressive LSTM                   | 동일 (더 안정적인 attention)           |
| Postnet       | 없음                                  | 5-layer CNN 보정                        |
| Vocoder       | Griffin-Lim (낮은 음질)               | WaveNet (고음질), 요즘은 HiFi-GAN 대체 |
| 출력          | Mel + Linear Spectrogram              | Mel-Spectrogram only                    |

---

## 🧠 장점 & 한계

### ✅ 장점
- 음질이 매우 뛰어남 (자연스러운 목소리)
- attention + postnet 조합으로 정렬/보정 안정화

### ⚠️ 한계
- Autoregressive → 느림
- Long sentence에서 attention collapse 발생 가능
- 실시간 응용 어려움 → FastSpeech로 대체됨

---

## 📚 논문 정보

- Title: *Natural TTS synthesis by conditioning Wavenet on Mel spectrogram predictions*
- Link: [https://arxiv.org/abs/1712.05884](https://arxiv.org/abs/1712.05884)
- Code (Unofficial): [https://github.com/NVIDIA/tacotron2](https://github.com/NVIDIA/tacotron2)

---

## ✅ 요약

| 항목      | 설명                                      |
|-----------|-------------------------------------------|
| 입력      | 텍스트 (char 또는 phoneme)               |
| 출력      | Mel-spectrogram                          |
| 구조      | Encoder (CNN+BiLSTM) → Attention → Decoder |
| 보정      | Postnet (CNN)                             |
| 음성화     | WaveNet 또는 HiFi-GAN으로 waveform 생성    |

> Tacotron 2는 End-to-End TTS의 **사실상 표준 구조**로,  
> 이후 FastSpeech, VITS 등 모든 모델의 **출발점**입니다.
