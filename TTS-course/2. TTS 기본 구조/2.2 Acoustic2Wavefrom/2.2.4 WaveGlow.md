# 🌪️ WaveGlow: A Flow-Based Generative Network for Speech Synthesis

---

## 📌 개요

**WaveGlow**는 NVIDIA가 발표한 **Flow 기반 vocoder**로  
**WaveNet의 고음질**과 **Parallel WaveGAN의 속도**를 **동시에 잡은** 모델입니다.

> 🎯 특징:
> - Autoregressive X → 병렬 생성 O  
> - 고품질 멜 → 음성 변환  
> - 단일 네트워크로 구성 (GAN 필요 없음)

---

## 🎯 핵심 아이디어

WaveGlow는 두 가지 아이디어를 결합한 모델:

| 원리            | 설명                                               |
|-----------------|----------------------------------------------------|
| **Glow (Flow)** | reversible한 transformation → density estimation 가능 |
| **WaveNet**     | 오디오를 조건부 모델링                             |

→ `mel-spectrogram → waveform` 변환을 flow 기반으로 직접 학습

---

## 🧬 전체 구조

```text
Input: mel-spectrogram (80 x T)
↓
Upsample mel to match waveform length
↓
Normal distribution sample z ~ N(0,1)
↓
Glow Blocks (Affine Coupling + 1x1 invertible conv)
↓
Output: waveform
```

---

## 🧪 작동 예시 (PyTorch 기반)

> NVIDIA 공식 코드 기반 추정 예시

```python
import torch
import numpy as np
import soundfile as sf
from waveglow import model as glow

# 1. Mel-spectrogram 불러오기 (예: 80 x T)
mel = np.load("mel_example.npy")
mel = torch.from_numpy(mel).unsqueeze(0).cuda()  # [1, 80, T]

# 2. WaveGlow 모델 로드
waveglow = torch.load('waveglow_256channels_universal_v5.pt')['model']
waveglow.cuda().eval()

# 3. Mel → waveform 변환
with torch.no_grad():
    waveform = waveglow.infer(mel, sigma=0.6).float().cpu().numpy()[0]

# 4. 저장
sf.write("waveglow_output.wav", waveform, samplerate=22050)
```

---

## ⚙️ 핵심 구성 요소

### 1️⃣ Invertible 1x1 Convolution
- 채널 혼합을 위한 가역적 컨볼루션
- `det(W)`를 사용해 log-likelihood 계산에 기여

---

### 2️⃣ Affine Coupling Layer

```text
x = [x_a, x_b]
y_a = x_a
y_b = x_b * exp(s(x_a)) + t(x_a)
→ reversible transformation
```

- 파라미터 `s()`와 `t()`는 작은 네트워크로 학습
- 역변환도 쉽게 가능 → `x_b = (y_b - t(x_a)) / exp(s(x_a))`

---

### 3️⃣ Flow Block (전체 구조 반복)

```text
z → [Flow1] → [Flow2] → ... → waveform
```

- 보통 12~20개의 flow block 사용
- 각 block: [ActNorm → Invertible Conv → Affine Coupling]

---

## 📈 시각화 예시 (Mel → Waveform)

```python
import librosa.display
import matplotlib.pyplot as plt

# mel 시각화
plt.figure(figsize=(10, 4))
librosa.display.specshow(mel.cpu()[0], sr=22050, hop_length=256, x_axis='time', y_axis='mel')
plt.title("Input Mel-spectrogram")
plt.colorbar()
plt.tight_layout()
plt.show()

# waveform 시각화
plt.figure(figsize=(10, 2))
plt.plot(waveform)
plt.title("WaveGlow Generated Waveform")
plt.tight_layout()
plt.show()
```

---

## 📊 Loss Function

- **Maximum Likelihood Estimation (MLE)**
- 입력을 `z ~ N(0, I)`로 맵핑한 후 log-likelihood 계산

```math
\log p(x) = \log p(z) + \sum \log | \det J |
```

> `J`: 전체 flow의 Jacobian  
> `|det J|`: affine 변환과 invertible conv에서 추출

---

## ✅ 장단점 요약

| 항목         | 장점                                   | 단점                              |
|--------------|----------------------------------------|-----------------------------------|
| 음질         | WaveNet 수준의 고음질                   | HiFi-GAN보다 약간 부자연스러움     |
| 속도         | 병렬 생성으로 매우 빠름                 | Diffusion vocoder에 비해 아직 느림  |
| 구조         | 단일 네트워크로 GAN 없이 학습 가능      | 메모리 사용량 큼 (flow 반복 구조)   |
| 안정성       | 안정적인 학습                          | 매우 깊은 네트워크 필요           |

---

## 📘 논문 정보

- **Title:** *WaveGlow: A Flow-based Generative Network for Speech Synthesis*
- **Authors:** Ryan Prenger et al. (NVIDIA, 2019)
- **Link:** https://arxiv.org/abs/1811.00002
- **Code:** https://github.com/NVIDIA/waveglow

---

## ✅ 정리

| 항목           | 설명                                   |
|----------------|----------------------------------------|
| 모델 종류      | Flow-based non-autoregressive vocoder  |
| 입력           | Mel-spectrogram                        |
| 출력           | Waveform (1D, float32)                 |
| 학습 방식      | Maximum Likelihood (MLE)               |
| 생성 방식      | 병렬 (sampling from Gaussian + inverse flow) |
| 주요 구성      | Affine Coupling, Invertible Conv       |

---

> 🎧 WaveGlow는 **WaveNet의 품질**과 **병렬성**을 모두 달성한  
> "Classic flow-based vocoder"로 이후 HiFi-GAN, DiffWave에 영향을 주었습니다.

