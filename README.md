# ğŸ§  TTSì˜ ì§„í™”: LLM ë“±ì¥ ì´ì „ vs ì´í›„

---

## ğŸ“š ëª©ì°¨

- [ğŸ—ï¸ LLM ë“±ì¥ ì´ì „ TTSì˜ ì›ë¦¬ (FastSpeech2 ê¸°ë°˜)](#llm-before)
- [ğŸ§  LLM ê¸°ë°˜ TTSì˜ ì‘ë™ ì›ë¦¬ (Semantic Token, Duration í¬í•¨)](#llm-after)


<h2 id="llm-before">ğŸ—ï¸ LLM ë“±ì¥ ì´ì „ TTSì˜ ì›ë¦¬ (FastSpeech2 ê¸°ë°˜ ì˜ˆì‹œ í¬í•¨)</h2>

---

## ğŸ¯ ê°œìš”

ì „í†µì ì¸ TTS ì‹œìŠ¤í…œì€ ë‹¤ìŒê³¼ ê°™ì€ **ëª¨ë“ˆí˜• íŒŒì´í”„ë¼ì¸**ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:

```
Text â†’ Text Normalization â†’ G2P â†’ Phoneme Embedding â†’ Duration Predictor
   â†’ Length Regulator â†’ Acoustic Model (e.g., Mel-spectrogram) â†’ Vocoder â†’ Waveform
```

ê° ë‹¨ê³„ëŠ” ë…ë¦½ì ì¸ ëª¨ë¸ ë˜ëŠ” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ êµ¬ì„±ë˜ë©°, ì „ì²´ ì‹œìŠ¤í…œì€ ë³‘ë ¬ ë˜ëŠ” ìˆœì°¨ì ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤.

---

## ğŸ“Œ ì „ì²´ êµ¬ì¡° (FastSpeech2 ê¸°ë°˜)



```mermaid
flowchart LR
    A[Text ì…ë ¥]
    B[Text Normalization]
    C["Grapheme-to-Phoneme - G2P"]
    D["Phoneme Embedding"]
    E["Duration Predictor"]
    F["Length Regulator"]
    G["Acoustic Model - Mel Predictor"]
    H["Vocoder - HiFi-GAN"]
    I[Waveform ì¶œë ¥]

    A --> B --> C --> D --> E --> F --> G --> H --> I
```



## ğŸ§ª ì˜ˆì‹œ: `"ì•ˆë…•í•˜ì„¸ìš”"`

### 1ï¸âƒ£ Text Normalization

ì…ë ¥ í…ìŠ¤íŠ¸ `"ì•ˆë…•í•˜ì„¸ìš”"`ëŠ” ìˆ«ì, ì•½ì–´, ê¸°í˜¸ ë“±ì„ ì •ê·œí™”í•©ë‹ˆë‹¤.  
ì´ ë¬¸ì¥ì€ ë‹¨ìˆœí•˜ì—¬ ë³€í™˜ ì—†ìŒ.

```text
"ì•ˆë…•í•˜ì„¸ìš”" â†’ "ì•ˆë…•í•˜ì„¸ìš”"
```

---

### 2ï¸âƒ£ G2P (Grapheme-to-Phoneme)

```python
Input: "ì•ˆë…•í•˜ì„¸ìš”"
â†’ Output: ["a", "n", "ny", "eo", "ng", "h", "a", "se", "yo"]
```

ì´ ê³¼ì •ì€ í•œê¸€ ìì†Œ/ìŒì†Œë¥¼ ì¶”ì¶œí•˜ê±°ë‚˜ ìŒìš´ ê·œì¹™ì— ë”°ë¼ ë³€í˜•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

### 3ï¸âƒ£ Phoneme Embedding

ê° ìŒì†ŒëŠ” ê³ ì •ëœ ì°¨ì›ì˜ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.

```python
embedding("a") â†’ xâ‚ âˆˆ â„Â²âµâ¶
embedding("n") â†’ xâ‚‚ âˆˆ â„Â²âµâ¶
...
```

ì „ì²´ ì‹œí€€ìŠ¤:
```python
X = [xâ‚, xâ‚‚, ..., xâ‚‰]  # (9, 256)
```

---

### 4ï¸âƒ£ Duration Prediction

ê° ìŒì†Œê°€ ëª‡ frame ê¸¸ì´ë¡œ ë°œìŒë ì§€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.

```python
durations = [5, 3, 4, 6, 2, 3, 5, 3, 4]  # ì´ frame ìˆ˜ = 35
```

---

### 5ï¸âƒ£ Length Regulator

Durationì— ë”°ë¼ ìŒì†Œ ì„ë² ë”©ì„ ì‹œê°„ ì¶•ìœ¼ë¡œ ë°˜ë³µí•©ë‹ˆë‹¤.

```python
expanded = []
for x, d in zip(phoneme_embeddings, durations):
    expanded.extend([x] * d)

expanded.shape = (35, 256)
```

---

### 6ï¸âƒ£ Acoustic Model (Mel predictor)

Length Regulator ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **Mel-spectrogram**ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.

```python
mel = acoustic_model(expanded)  # mel.shape = (35, 80)
```

---

### 7ï¸âƒ£ Vocoder

Mel-spectrogram â†’ Waveform ë³€í™˜

```python
waveform = vocoder(mel)  # torch.Size([56000]) for 3.5ì´ˆ at 16kHz
```

---

## ğŸ“ ìˆ˜ì‹ ìš”ì•½

1. ì„ë² ë”©
   $$x_i = \text{Embedding}(p_i), \quad \text{where } p_i \text{ is the i-th phoneme}$$

2. Duration ì˜ˆì¸¡
   $$d_i = \text{DurationPredictor}(x_i)$$

3. Length Regulator
   $$\tilde{X} = \bigcup_{i=1}^{N} [x_i]^{\times d_i}$$

4. Mel ì˜ˆì¸¡
   $$\hat{Y}_{mel} = \text{AcousticModel}(\tilde{X})$$

5. Waveform ìƒì„±
   $$\hat{y} = \text{Vocoder}(\hat{Y}_{mel})$$

---

## ğŸ“Š ê° êµ¬ì„±ìš”ì†Œ ë¹„êµ

| êµ¬ì„± ìš”ì†Œ | ì—­í•  | ì˜ˆì‹œ ëª¨ë¸ |
|-----------|------|------------|
| Text Normalizer | ê¸°í˜¸/ìˆ«ì ì •ê·œí™” | hand-crafted |
| G2P | ìì†Œ/ìŒì†Œ ë³€í™˜ | KoG2P, g2pk |
| Embedding | ìŒì†Œ ì„ë² ë”© | 256~512D |
| Duration Predictor | ë°œìŒ ê¸¸ì´ ì˜ˆì¸¡ | FastSpeech2 ë‚´ë¶€ |
| Length Regulator | ì‹œê°„ì¶• í™•ì¥ | FastSpeech ì‹œê·¸ë‹ˆì²˜ |
| Acoustic Model | Mel ì˜ˆì¸¡ | Transformer |
| Vocoder | Mel â†’ Waveform | HiFi-GAN, WaveGlow, WaveNet |

 <h2 id="llm-after">ğŸ§  LLM ê¸°ë°˜ TTSì˜ ì‘ë™ ì›ë¦¬ (Semantic Token, Duration í¬í•¨ ìƒì„¸ ì„¤ëª…)</h2>

---

## âœ… ì „ì²´ êµ¬ì¡° ê°œìš”

```
Text
 â†“
[Semantic Encoder (GPT ê¸°ë°˜)]
 â†“
Semantic Tokens  â† ì˜ë¯¸ ë‹¨ìœ„ í† í° (ë™ìŒì´ì˜ì–´ êµ¬ë¶„ í¬í•¨)
 â†“
[Speech LLM Decoder]
 â†“
Acoustic Tokens  â† duration, pitch, timbre ë“± í¬í•¨
 â†“
[Vocoder]
 â†“
Waveform
```

---

## ğŸ§  í•µì‹¬ ì•„ì´ë””ì–´

LLM ê¸°ë°˜ TTSëŠ” ê¸°ì¡´ TTSì™€ ë‹¤ë¥´ê²Œ, í…ìŠ¤íŠ¸ë¥¼ ì§ì ‘ Mel-spectrogramìœ¼ë¡œ ì˜ˆì¸¡í•˜ê±°ë‚˜ ìŒì„± ì‹ í˜¸ë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.  
ëŒ€ì‹  ë‹¤ìŒê³¼ ê°™ì€ 3ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:

1. **í…ìŠ¤íŠ¸ â†’ ì˜ë¯¸ í† í°(Semantic Token)**  
2. **ì˜ë¯¸ í† í° â†’ ì†Œë¦¬ í† í°(Acoustic Token)**  
3. **ì†Œë¦¬ í† í° â†’ ì‹¤ì œ waveform**  

ì´ëŸ¬í•œ êµ¬ì¡°ëŠ” ê¸°ì¡´ TTSë³´ë‹¤ ìì—°ìŠ¤ëŸ¬ìš´ ì–µì–‘, ê°ì •, í™”ì ë³´ì¡´ì´ í›¨ì”¬ ë›°ì–´ë‚©ë‹ˆë‹¤.

---

## 1ï¸âƒ£ Semantic Token: ì˜ë¯¸ ê¸°ë°˜ í† í°

### ğŸ“Œ ì •ì˜
- í…ìŠ¤íŠ¸ ë¬¸ì¥ì—ì„œ **"ë¬´ì—‡ì„ ë§í•  ê²ƒì¸ê°€"**ë¥¼ í‘œí˜„í•˜ëŠ” ë‹¨ìœ„.
- ì¼ë°˜ wordpiece í† í°ì´ ì•„ë‹Œ, **ìŒì„± ìƒì„±ì„ ìœ„í•œ ì˜ë¯¸ í‘œí˜„ ë‹¨ìœ„**ë¡œ í•™ìŠµë¨.

### ğŸ” í•™ìŠµ ë°©ì‹
- ëŒ€ê·œëª¨ í…ìŠ¤íŠ¸-ìŒì„± ë°ì´í„°ì—ì„œ **self-supervised ë°©ì‹ìœ¼ë¡œ joint representation í•™ìŠµ**
- ì˜ˆì‹œ: GPTë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ í…ìŠ¤íŠ¸ ì¸ì½”ë”ì™€ ì˜¤ë””ì˜¤ ì¸ì½”ë”ë¥¼ aligní•˜ì—¬ í•™ìŠµ

### ğŸ¯ í•µì‹¬ ê¸°ëŠ¥
| ê¸°ëŠ¥ | ì„¤ëª… |
|------|------|
| ì˜ë¯¸ ë¶„ë³„ | ë™ìŒì´ì˜ì–´ë„ ë¬¸ë§¥ì— ë”°ë¼ êµ¬ë¶„ë¨ |
| ë°œí™” ì˜ë„ ë°˜ì˜ | ì§ˆë¬¸/ëª…ë ¹/ì˜ë¬¸ ê°™ì€ ë¬¸ì¥ í–‰ìœ„ êµ¬ë¶„ |
| ì–µì–‘ íŒíŠ¸ ë‚´í¬ | prosody ì˜ˆì¸¡ì— ìœ ë¦¬í•œ token ë¶„ë¦¬ |

### ğŸ§  ì˜ˆì‹œ
```
ì…ë ¥: "ë‚˜ëŠ” ì€í–‰ì— ê°„ë‹¤."
Semantic Tokens = [201, 834, 2, 911, 421]
(ì—¬ê¸°ì„œ 834ëŠ” ë¬¸ë§¥ìƒ 'ê¸ˆìœµê¸°ê´€' ì˜ë¯¸ë¡œ ì„ íƒë¨)
```

---

## 2ï¸âƒ£ Duration í¬í•¨ Acoustic Token ìƒì„±

### ğŸ› ï¸ ì—­í• 
- Speech LLMì€ semantic token ì‹œí€€ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ **acoustic token ì‹œí€€ìŠ¤**ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
- ì´ tokenë“¤ì€ ë‹¤ìŒ ìš”ì†Œë¥¼ ëª¨ë‘ ì•”ë¬µì ìœ¼ë¡œ í¬í•¨í•©ë‹ˆë‹¤:
  - **Duration**: ê° ìŒì†Œë¥¼ ì–¼ë§ˆë‚˜ ê¸¸ê²Œ ë§í• ì§€
  - **Pitch**: ë†’ë‚®ì´
  - **Timbre**: í™”ì ìŒìƒ‰
  - **Prosody**: ì–µì–‘ íë¦„

### ğŸ” Duration í‘œí˜„ ë°©ì‹
FastSpeech2ì²˜ëŸ¼ ëª…ì‹œì ì¸ duration prediction ëŒ€ì‹ , **token ë°˜ë³µ íšŸìˆ˜ë¡œ ê°„ì ‘ í‘œí˜„**ë©ë‹ˆë‹¤.

ì˜ˆì‹œ:
```text
Semantic Token: [201, 834, 2, 911, 421]
 â†“
Acoustic Token: [78, 32, 32, 32, 87, ..., 208]
```

â†’ ì—¬ê¸°ì„œ `32`ê°€ 3ë²ˆ ë°˜ë³µ â†’ íŠ¹ì • ìŒì†Œê°€ **3 í”„ë ˆì„ ê¸¸ì´**ë¡œ í‘œí˜„ë¨

---

## 3ï¸âƒ£ Vocoder: Acoustic Token â†’ Waveform

- acoustic tokenì€ `EnCodec`, `SoundStream` ë“±ìœ¼ë¡œ ì–‘ìí™”ëœ discrete code indexì…ë‹ˆë‹¤.
- VocoderëŠ” ì´ token ì‹œí€€ìŠ¤ë¥¼ waveformìœ¼ë¡œ ë³µì›í•©ë‹ˆë‹¤.

```python
waveform = vocoder(acoustic_tokens)  # e.g., 24kHz waveform ì¶œë ¥
```

---

## ğŸ§© ì „ì²´ ì˜ˆì‹œ: Bark ìŠ¤íƒ€ì¼

### ì…ë ¥ í…ìŠ¤íŠ¸
```
"Hello, my name is Alice."
```

### ì²˜ë¦¬ ì˜ˆì‹œ
```python
# Step 1: Semantic Encoding
semantic_tokens = [428, 1002, 201, 7, 844, 391, 387]

# Step 2: Acoustic Decoding
acoustic_tokens = [
    78, 32, 32, 32,    # "Hel..."
    120, 203, 1,       # "lo,"
    92, 92,            # "my"
    ...
]  # ì´ 1024 tokens

# Step 3: Waveform reconstruction
waveform = vocoder(acoustic_tokens)
```

---

## ğŸ“ ìˆ˜ì‹ ìš”ì•½

1. í…ìŠ¤íŠ¸ â†’ ì˜ë¯¸ í† í°
   $$S_{1:N} = f_{\text{semantic}}(\text{Text})$$

2. ì˜ë¯¸ í† í° â†’ ìŒí–¥ í† í° (duration í¬í•¨)
   $$A_{1:T} = f_{\text{acoustic}}(S_{1:N})$$

3. ìŒí–¥ í† í° â†’ íŒŒí˜•
   $$hat{y}_{1:L} = text{Vocoder}(A_{1:T})$$

---

## ğŸ“Š Semantic vs Acoustic Token ë¹„êµ

| í•­ëª© | Semantic Token | Acoustic Token |
|------|----------------|----------------|
| ì˜ë¯¸ | ë¬´ì—‡ì„ ë§í• ì§€ | ì–´ë–»ê²Œ ë§í• ì§€ |
| ì—­í•  | ì˜ë¯¸/ë¬¸ë§¥/ë¬¸ì¥ ì˜ë„ í‘œí˜„ | duration/pitch/timbre í¬í•¨ |
| í˜•ì‹ | ì •ìˆ˜ ì¸ë±ìŠ¤ (e.g., 428) | codebook index (e.g., 78) |
| ê¸¸ì´ | ìˆ˜ì‹­ ê°œ | ìˆ˜ë°±~ì²œ ê°œ |
| ì˜ˆì‹œ ëª¨ë¸ | GPT encoder | GPT-style decoder |

---

## âœ… ê²°ë¡ 

- Semantic tokenì€ **ë¬¸ë§¥ ê¸°ë°˜ ì˜ë¯¸ ë‹¨ìœ„**, ë™ìŒì´ì˜ì–´ì™€ ì–µì–‘ íŒíŠ¸ê¹Œì§€ í¬í•¨
- Acoustic tokenì€ **ìŒí–¥ ì •ë³´ë¥¼ ì„¸ë°€í•˜ê²Œ ë¶„í•´í•œ discrete í‘œí˜„**
- Durationì€ token ë°˜ë³µ íšŸìˆ˜ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ í‘œí˜„ë˜ë©°, ëª…ì‹œì  ì˜ˆì¸¡ì´ í•„ìš” ì—†ìŒ
- ì „ì²´ íŒŒì´í”„ë¼ì¸ì€ end-to-endì´ë©°, ê°ì •Â·í™”ì ë³´ì¡´Â·ìì—°ìŠ¤ëŸ¬ìš´ ë°œí™” ê°€ëŠ¥

---

## ğŸ” ì°¸ê³  ëª¨ë¸ ìš”ì•½

| ëª¨ë¸ëª… | Semanticâ†’Acoustic ë°©ì‹ | Duration í‘œí˜„ |
|--------|------------------------|----------------|
| **Bark** | End-to-End LLM | Token ë°˜ë³µ |
| **AudioLM** | Multi-stage LMs | Token ì‹œê³„ì—´ |
| **VALL-E** | Prompt + Text â†’ token | ê³ ì • ê¸¸ì´ í”„ë ˆì„ |
| **SoundStorm** | AR token generator | ì •ë ¬ëœ time-synced token |

---

## ğŸ—ºï¸ Mermaid ë‹¤ì´ì–´ê·¸ë¨

### ğŸ“Œ êµ¬ì¡° íë¦„ë„

```mermaid
flowchart LR
    A[Text ì…ë ¥] --> B[Semantic Encoder]
    B --> C[Semantic Tokens]
    C --> D[Speech LLM Decoder]
    D --> E[Acoustic Tokens]
    E --> F[Vocoder]
    F --> G[Waveform ì¶œë ¥]
```

---

### ğŸ•’ ì²˜ë¦¬ ìˆœì„œ ì‹œí€€ìŠ¤

```mermaid
sequenceDiagram
    participant User as ì‚¬ìš©ì
    participant LLM as Semantic Encoder
    participant SpeechLM as Speech Decoder
    participant Voc as Vocoder

    User->>LLM: "ë‚˜ëŠ” ì€í–‰ì— ê°„ë‹¤."
    LLM-->>SpeechLM: Semantic Tokens (ë¬¸ë§¥ í¬í•¨)
    SpeechLM-->>Voc: Acoustic Tokens (duration, pitch ë“± í¬í•¨)
    Voc-->>User: ìŒì„± waveform ì¶œë ¥
```

---

### ğŸ§¬ Duration í‘œí˜„ ë°©ì‹ ì˜ˆì‹œ

```mermaid
graph TD
    P1["ìŒì†Œ: 'ny'"] --> T1["Acoustic Token: 32"]
    T1 --> T2["ë°˜ë³µ: 3ë²ˆ"]
    T2 --> D1["â†’ 3í”„ë ˆì„ ê¸¸ì´ (37.5ms @ 80fps)"]
```
---

## âœ… ê²°ë¡ 

- LLM ì´ì „ TTSëŠ” **ëª¨ë“ˆí™”ë˜ê³  í•´ì„ ê°€ëŠ¥í•œ êµ¬ì¡°**ì˜€ìŒ
- Durationì€ **ëª…ì‹œì ìœ¼ë¡œ ì˜ˆì¸¡**ë˜ë©°, ì–µì–‘ì´ë‚˜ ê¸¸ì´ ì¡°ì ˆì´ ê°€ëŠ¥í–ˆìŒ
- ë‹¨ì : íŒŒì´í”„ë¼ì¸ ë³µì¡, ê°ì •/ìì—°ìŠ¤ëŸ¬ì›€ í‘œí˜„ í•œê³„
- ì¥ì : ëª¨ë¸ ë””ë²„ê¹… ë° ë¶„ì„ ìš©ì´

