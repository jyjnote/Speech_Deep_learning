# ğŸ—£ï¸ CosyVoice2 LJSpeech í•™ìŠµ ì „ì²´ íŒŒì´í”„ë¼ì¸

> ì´ ë¬¸ì„œëŠ” LJSpeech ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ì—¬ CosyVoice2 ëª¨ë¸ì„ í•™ìŠµí•˜ê¸° ìœ„í•œ ì „ì²´ ê³¼ì •ì„ ì •ë¦¬í•œ ê²ƒì…ë‹ˆë‹¤.

---

## ğŸ“‚ ë””ë ‰í† ë¦¬ êµ¬ì„± ì˜ˆì‹œ

```
CosyVoice2/
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ prepare_ljspeech.py
â”‚   â”œâ”€â”€ extract_embedding.py
â”‚   â”œâ”€â”€ extract_speech_token.py
â”‚   â””â”€â”€ make_parquet_list.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ ljspeech/
â”‚       â”œâ”€â”€ wav.scp
â”‚       â”œâ”€â”€ text
â”‚       â”œâ”€â”€ utt2spk
â”‚       â”œâ”€â”€ spk2utt
â”‚       â””â”€â”€ parquet/
â”œâ”€â”€ pretrained_models/
â”‚   â””â”€â”€ CosyVoice2-0.5B/
â”‚       â”œâ”€â”€ campplus.onnx
â”‚       â”œâ”€â”€ speech_tokenizer_v2.onnx
â”‚       â”œâ”€â”€ llm.pt
â”‚       â”œâ”€â”€ flow.pt
â”‚       â”œâ”€â”€ hift.pt
â”‚       â””â”€â”€ CosyVoice-BlankEN/
â””â”€â”€ configs/
    â””â”€â”€ train_ljspeech.yaml
```

---

## âœ… ë‹¨ê³„ë³„ ìš”ì•½í‘œ

| Stage | ì„¤ëª…                          | LJSpeech ë³€ê²½ì‚¬í•­                      |
|-------|-------------------------------|----------------------------------------|
| -1    | LibriTTS ë‹¤ìš´ë¡œë“œ              | âŒ ë¶ˆí•„ìš” (LJSpeechëŠ” ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ)         |
| 0     | utt2spk, text, wav.scp ìƒì„±   | âœ… `prepare_ljspeech.py` ì‚¬ìš©           |
| 1     | Speaker embedding ì¶”ì¶œ        | âœ… `campplus.onnx` ì‚¬ìš©, ë™ì¼ ì ìš© ê°€ëŠ¥ |
| 2     | Speech token ì¶”ì¶œ             | âœ… `speech_tokenizer_v2.onnx` ì‚¬ìš©     |
| 3     | Parquet ìƒì„± (`.tar` ì €ì¥)    | âœ… ë™ì¼ ë°©ì‹ ì‚¬ìš©                       |
| 4     | í•™ìŠµ ë¦¬ìŠ¤íŠ¸ ì¤€ë¹„              | âœ… `data.list` ë³µì‚¬                    |
| 5     | ëª¨ë¸ í•™ìŠµ (LLM ë“±)            | âœ… ê²½ë¡œë§Œ ì¡°ì •                         |
| 6     | Checkpoint average            | âœ… ë™ì¼ ì‚¬ìš© ê°€ëŠ¥                      |
| 7     | ëª¨ë¸ export (JIT, ONNX)       | âœ… ë™ì¼ ì‚¬ìš© ê°€ëŠ¥                      |

---

## ğŸ”§ Step-by-step ëª…ë ¹ì–´

### âœ… Step 1: utt2spk, text, wav.scp ìƒì„±

```bash
python tools/prepare_ljspeech.py \
  --src_dir /mnt/jjy/CosyVoice2/LJSpeech \
  --des_dir data/ljspeech
```

> ìƒì„±ë˜ëŠ” íŒŒì¼:
> - `data/ljspeech/wav.scp`
> - `data/ljspeech/text`
> - `data/ljspeech/utt2spk`
> - `data/ljspeech/spk2utt`

---

### âœ… Step 2: Speaker Embedding ì¶”ì¶œ

```bash
python tools/extract_embedding.py \
  --dir data/ljspeech \
  --onnx_path pretrained_models/CosyVoice2-0.5B/campplus.onnx \
  --num_thread 8
```

> ìƒì„±ë˜ëŠ” íŒŒì¼:
> - `utt2embedding.pt`, `spk2embedding.pt`

---

### âœ… Step 3: Speech Token ì¶”ì¶œ

```bash
CUDA_VISIBLE_DEVICES=7 python tools/extract_speech_token.py \
  --dir data/ljspeech \
  --onnx_path pretrained_models/CosyVoice2-0.5B/speech_tokenizer_v2.onnx \
  --num_thread 8
```

> ìƒì„±ë˜ëŠ” íŒŒì¼:
> - `utt2speech_token.pt`

---

### âœ… Step 4: Parquet ìƒì„±

```bash
mkdir -p data/ljspeech/parquet

python tools/make_parquet_list.py \
  --src_dir data/ljspeech \
  --des_dir data/ljspeech/parquet \
  --num_utts_per_parquet 1000 \
  --num_processes 10
```

> ìƒì„±ë˜ëŠ” íŒŒì¼ë“¤:
> - `parquet_000000000.tar`, ...
> - `data.list`, `utt2data.list`, `spk2data.list`

---

### âœ… Step 5: í•™ìŠµ ë¦¬ìŠ¤íŠ¸ ë³µì‚¬

```bash
cp data/ljspeech/parquet/data.list data/train.data.list
cp data/ljspeech/parquet/data.list data/dev.data.list
```

---

### âœ… Step 6: LLM í•™ìŠµ ì‹œì‘ (GPU 7ë²ˆ)

```bash
export PYTHONPATH=$(pwd):$(pwd)/third_party/Matcha-TTS

CUDA_VISIBLE_DEVICES=7 torchrun --nnodes=1 --nproc_per_node=1 \
  --rdzv_id=ljs_train --rdzv_backend="c10d" --rdzv_endpoint="localhost:1234" \
  cosyvoice/bin/train.py \
  --train_engine torch_ddp \
  --config configs/train_ljspeech.yaml \
  --train_data data/train.data.list \
  --cv_data data/dev.data.list \
  --qwen_pretrain_path pretrained_models/CosyVoice2-0.5B/CosyVoice-BlankEN \
  --model llm \
  --checkpoint pretrained_models/CosyVoice2-0.5B/llm.pt \
  --model_dir exp/ljspeech/llm \
  --tensorboard_dir tensorboard/ljspeech/llm \
  --ddp.dist_backend nccl \
  --num_workers 2 \
  --prefetch 100 \
  --pin_memory \
  --use_amp
```

> `train_ljspeech.yaml` ì˜ˆì‹œ ì„¤ì •:
> ```yaml
> dataset:
>   sample_rate: 22050
>   hop_size: 256
>   win_size: 1024
>   n_fft: 1024
>   fmin: 80
>   fmax: 7600
> ```

---

## ğŸ“Š Step 7: ë¡œê·¸ ê¸°ë°˜ ì‹œê°í™” (ì„ íƒ)

```bash
python3 -c "
import matplotlib.pyplot as plt, re
losses, accs, steps = [], [], []
with open('train.log') as f:
    for line in f:
        if 'DEBUG TRAIN Batch' in line:
            m = re.search(r'loss ([\d\.]+) acc ([\d\.]+)', line)
            if m:
                losses.append(float(m.group(1)))
                accs.append(float(m.group(2)))
                steps.append(len(losses))
if losses:
    plt.figure(figsize=(10,4))
    plt.subplot(1,2,1); plt.plot(steps, losses); plt.title('Loss'); plt.grid()
    plt.subplot(1,2,2); plt.plot(steps, accs); plt.title('Accuracy'); plt.grid()
    plt.tight_layout(); plt.savefig('training_progress.png'); print('âœ… saved.')
else:
    print('âŒ No matching logs.')
"
```

---

## âœ… ì´í›„ ì‘ì—…

- `flow` ëª¨ë¸ í•™ìŠµ
- `hifigan` í•™ìŠµ
- `average_model.py`ë¡œ ì²´í¬í¬ì¸íŠ¸ í‰ê· 
- `export_jit.py`, `export_onnx.py`ë¡œ ì¶”ë¡ ìš© ëª¨ë¸ ë³€í™˜

---
